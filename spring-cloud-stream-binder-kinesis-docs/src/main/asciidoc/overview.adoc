[partintro]
--
This guide describes the https://aws.amazon.com/kinesis/[AWS Kinesis] implementation of the Spring Cloud Stream Binder.
It contains information about its design, usage and configuration options, as well as information on how the Stream Cloud Stream concepts map into AWS Kinesis specific constructs.
--

== Usage

For using the AWS Kinesis Binder, you just need to add it to your Spring Cloud Stream application, using the following Maven coordinates:

[source,xml]
----
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-stream-binder-kinesis</artifactId>
</dependency>
----

== Kinesis Binder Overview

The Spring Cloud Stream Binder for AWS Kinesis provides the binding implementation for the Spring Cloud Stream.
This implementation uses Spring Integration AWS Kinesis Channel Adapters at its foundation.
The following captures how the Kinesis Binder implementation maps each of the configured destination to a AWS Kinesis Streams:

.Kinesis Binder
image::images/kinesis-binder.png[width=300,scaledwidth="50%"]

Unlike https://kafka.apache.org/[Apache Kafka] the AWS Kinesis doesn't provide out-of-the-box support for consumer groups.
The support of this feature is implemented as a part of `MetadataStore` key for shard checkpoints in the `KinesisMessageDrivenChannelAdapter` - `[CONSUMER_GROUP]:[STREAM]:[SHARD_ID]`.
This way all the `ShardConsumer` s in the same consumer group may receive the same records from the same shard but they will be filtered according the latest stored `sequenceNumber` after performing checkpoint.

The partitioning logic in AWS Kinesis is similar to the Apache Kafka support, but with slightly different logic.
The `partitionKey` on the producer side determines which shard in the stream the data record is assigned to.
Partition keys are Unicode strings with a maximum length limit of 256 characters for each key.
AWS Kinesis uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard.
Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards.
As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream.
But at the same time we can't select target shard to send explicitly.
Although calculating the hash manually (and use `explicitHashKeyExpression` for producer, respectively), we may track the target shard by inclusion into its `HashKeyRange`.

By default partition key is a result of the `Object.hash()` from the message `payload`.

The Spring Cloud Stream partition handling logic is excluded in case of AWS Kinesis Binder since it is out of use and the provided `producer.partitionKeyExpression` is propagated to the `KinesisMessageHandler` directly.

On the consumer side the `instanceCount` and `instanceIndex` are used to distribute shards between consumers in group evenly.

== Configuration Options

This section contains settings specific to the Kinesis Binder and bound channels.

For general binding configuration options and properties, please refer to the https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-core-docs/src/main/asciidoc/spring-cloud-stream-overview.adoc#configuration-options[Spring Cloud Stream core documentation].

[[kinesis-binder-properties]]
=== Kinesis Binder Properties

The following properties are available for Kinesis Binder configuration, which start with the `spring.cloud.stream.kinesis.binder.` prefix

headers::
  The set of custom headers to transfer over AWS Kinesis
+
Default: "correlationId", "sequenceSize", "sequenceNumber", "contentType", "originalContentType".
describeStreamBackoff::
  The amount of time in milliseconds in between retries for the `DescribeStream` operation
+
Default: `1000`.
describeStreamRetries::
  The amount of times the consumer will retry a `DescribeStream` operation waiting for the stream to be in `ACTIVE` state
+
Default: `50`.
autoAddShards::
    If set to `true`, the binder will create new shards automatically.
If set to `false`, the binder will rely on the shard size of the stream being already configured.
If the shard count of the target stream is smaller than the expected value, the binder will ignore that value
+
Default: `false`
minShardCount::
    Effective only if `autoAddShards` is set to `true`.
The minimum number of shards that the binder will configure on the stream from which it produces/consumes data.
It can be superseded by the `partitionCount` setting of the producer or by the value of `instanceCount * concurrency` settings of the producer (if either is larger)
+
Default: `1`

The based on the DynamoDB Checkpoint properties prefixed with `spring.cloud.stream.kinesis.binder.checkpoint.`

table::
	The name to give the DynamoDb table
+
Default: `checkpoint`
createDelay::
    The amount of time in seconds between each polling attempt while waiting for the checkpoint DynamoDB table to be created
+
Default: `1`
createRetries::
    The amount of times the consumer will poll DynamoDB while waiting for the checkpoint table to be created
+
Default: `25`
readCapacity::
	The Read capacity of the DynamoDb table.
See http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html[Kinesis Provisioned Throughput]
+
Default: `1`
writeCapacity::
	The write capacity of the DynamoDb table.
See http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html[Kinesis Provisioned Throughput]
+
Default: `1`

=== Kinesis Consumer Properties

The following properties are available for Kinesis consumers only and must be prefixed with `spring.cloud.stream.kinesis.bindings.<channelName>.consumer.`

startTimeout::
  The amount of time to wait for the consumer to start, in milliseconds.
+
Default: `60000`.
listenerMode::
  The mode in which records are processed.
  If `record`, each `Message` will contain `byte[]` from a single `Record.data`.
  If `batch`, each `Message` will contain a `List<byte[]>` extracted from the consumed records.
  If `rawRecords`, each `Message` will non-converted `List<Record>`.
+
Default: `record`
checkpointMode::
  The mode in which checkpoints are updated. If `record`, checkpoints occur after each record is processed (but this option
  is only effective if `listenerMode` is set to `record`). If `batch`, checkpoints occur after each batch of records is
  processed. If `manual`, checkpoints occur on demand via the `Checkpointer` callback.
+
Default: `batch`
recordsLimit::
  The maximum number of records to poll per `GetRecords` request. Must not be greater than `10000`.
+
Default: `10000`
idleBetweenPolls::
  The sleep interval used in the main loop between shards polling cycles, in milliseconds. Must not be less than `250`
+
Default: `1000`
consumerBackoff::
  The amount of time the consumer will wait to attempt another `GetRecords` operation after a read with no results, in milliseconds.
+
Default: `1000`
shardIteratorType::
  The `com.amazonaws.services.kinesis.model.ShardIteratorType` name with an optional `sequenceNumber` for the `AT_SEQUENCE_NUMBER/AFTER_SEQUENCE_NUMBER` or milliseconds for the `AT_TIMESTAMP` after `:`.
  For example: `AT_TIMESTAMP:1515090166767`.
+
Default: `LATEST` for anonymous groups and `TRIM_HORIZON` otherwise.

NOTE: When `TRIM_HORIZON` shard iterator type is used, we need to take into account the time lag which happens during pointing the `ShardIterator` to the last untrimmed record in the shard in the system (the oldest data record in the shard).
So the `getRecords()` will move from that point to the last point, which takes time.
It is by default 1 day and it can be extended to 7 days.
This happens only for new consumer groups.
Any subsequent starts of the consumer in the same group are adjusted according the stored checkpoint via `AFTER_SEQUENCE_NUMBER` iterator type.

=== Kinesis Producer Properties

The following properties are available for Kinesis producers only and must be prefixed with `spring.cloud.stream.kinesis.bindings.<channelName>.producer.`

sync::
  Whether the producer should act in a synchronous manner with respect to writing records into a stream. If true, the producer will
  wait for a response from Kinesis after a `PutRecord` operation.
+
Default: `false`
sendTimeout::
  Effective only if `sync` is set to `true`. The amount of time to wait for a response from Kinesis after a `PutRecord` operation, in milliseconds.
+
Default: `10000`


[[kinesis-error-channels]]
== Error Channels

The binder can be configured to send producer exceptions to an error channel.
See https://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/#_spring_integration_error_channel_support[the section on Spring Cloud error channel support] for more information.

The payload of the `ErrorMessage` for a send failure is an `AwsRequestFailureException` with properties:

* `failedMessage` - the spring-messaging `Message<?>` that failed to be sent.
* `request` - the raw `AmazonWebServiceRequest` (either `PutRecordRequest` or `PutRecordsRequest`) that was created from the `failedMessage`.

There is no automatic handling of these exceptions (such as sending to a dead letter queue), but you can consume these exceptions with your own Spring Integration flow.

